# üè† Magicbricks RAG Chatbot (Production-Ready)

A production-grade Retrieval-Augmented Generation (RAG) chatbot for property search using:
- **Pinecone** for vector storage
- **Groq** for LLM generation  
- **Apify** for web scraping
- **FastAPI** for REST API
- **Smart scraping** for dynamic property discovery

## üéØ Key Features

### Production-Grade Architecture
- ‚úÖ Smart scraper with dynamic search
- ‚úÖ Comprehensive error handling with retry logic
- ‚úÖ Structured logging throughout
- ‚úÖ Health monitoring & metrics
- ‚úÖ Input validation (Pydantic)
- ‚úÖ Deduplication in vector DB
- ‚úÖ Configuration validation
- ‚úÖ FastAPI with CORS support

### User Features
- Real-time property search
- Natural language queries
- Source attribution
- Multi-city support
- Price/BHK/location filtering

## üöÄ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Environment

Create `.env` file:
```env
# Required
PINECONE_API_KEY=your_pinecone_key
GROQ_API_KEY=your_groq_key

# For scraping (optional but recommended)
APIFY_API_TOKEN=your_apify_token
```

### 3. Validate Setup

```bash
python config_validator.py
```

### 4. Populate Database

```bash
# Default: Scrapes Mumbai, Bangalore, Delhi
python data_pipeline.py

```

### 5. Start Server

```bash
# Development
uvicorn main:app --reload --port 8000

# Production  
uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

### 6. Open Browser
Navigate to: `http://localhost:8000`

## üìÅ Project Structure

```
Magic bricks/
‚îú‚îÄ‚îÄ main.py                    # FastAPI app (production-ready)
‚îú‚îÄ‚îÄ rag_chatbot.py            # RAG pipeline with retry logic
‚îú‚îÄ‚îÄ data_pipeline.py          # ETL with smart scraper
‚îú‚îÄ‚îÄ smart_scraper.py          # Dynamic property search
‚îú‚îÄ‚îÄ config.py                 # Configuration
‚îú‚îÄ‚îÄ config_validator.py       # Validation tool
‚îú‚îÄ‚îÄ health_monitor.py         # Health checks & metrics  
‚îú‚îÄ‚îÄ check_database.py         # DB inspection tool
‚îú‚îÄ‚îÄ PRODUCTION_CHECKLIST.md   # Deployment guide
‚îî‚îÄ‚îÄ static/                   # Frontend UI
```

## üõ†Ô∏è Usage Examples

### Check System Health
```bash
curl http://localhost:8000/health
```

### Query Properties
```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "3BHK in Mumbai under 2 crores", "top_k": 5}'
```

### Custom Property Search
```python
from smart_scraper import SmartPropertySearch

searcher = SmartPropertySearch()
properties = searcher.scrape_user_preferences({
    'city': 'Mumbai',
    'bhk': '3',
    'property_type': 'apartment',
    'min_price': 50,
    'max_price': 200
})
```

## üèóÔ∏è Production Architecture

```
User Query ‚Üí FastAPI ‚Üí Input Validation ‚Üí RAG Pipeline
                                            ‚Üì
Query Embedding ‚Üí Pinecone Search ‚Üí LLM Generation ‚Üí Response
    (retry)         (with dedup)        (retry)
```

### Data Flow
1. **Smart Scraper**: User preferences ‚Üí Search URL ‚Üí Extract listings ‚Üí Scrape details
2. **Processing**: Raw HTML ‚Üí Cleaned data ‚Üí Chunks ‚Üí Embeddings
3. **Storage**: Deduplicated vectors ‚Üí Pinecone (with metadata)
4. **Retrieval**: Query embedding ‚Üí Top-K search ‚Üí Context building
5. **Generation**: Context + Query ‚Üí Groq LLM ‚Üí Response

## üîç Monitoring & Debugging

### Check Database
```bash
python check_database.py
```

### Validate Config
```bash
python config_validator.py
```

### Health Check
```bash
curl http://localhost:8000/health | jq
```

## üìä Performance

- **Query Latency**: ~2-3s (retrieval + generation)
- **Pinecone Query**: ~150ms
- **Groq Generation**: ~1-2s
- **Throughput**: ~20 queries/min (single instance)

## üö® Common Issues

| Issue | Solution |
|-------|----------|
| "No properties found" | Run `python data_pipeline.py` |
| "Apify credits exhausted" | Add credits at console.apify.com |
| "Pinecone connection failed" | Verify API key in `.env` |
| Slow responses | Check `/health` for component latency |

## üîí Security (Production)

Before deploying:
- [ ] Restrict CORS origins (not `*`)
- [ ] Add rate limiting
- [ ] Enable API authentication
- [ ] Use secrets manager (not `.env`)
- [ ] Enable HTTPS

See [PRODUCTION_CHECKLIST.md](PRODUCTION_CHECKLIST.md) for full list.

## üìà Scaling

### Horizontal Scaling
```bash
uvicorn main:app --workers 4 --host 0.0.0.0
```

### Caching Layer
- Add Redis for frequent queries
- TTL: 1 hour recommended

### Database
- Pinecone serverless auto-scales
- Consider dedicated for >1M vectors

## ‚öôÔ∏è Configuration

Environment variables (`.env`):
```env
# Required
PINECONE_API_KEY=
GROQ_API_KEY=

# Optional
APIFY_API_TOKEN=
PINECONE_INDEX_NAME=magic
GROQ_MODEL=llama-3.3-70b-versatile
TEMPERATURE=0.1
MAX_TOKENS=1000
TOP_K=5
```

## üîí Privacy & Legal

This project includes sample data for demonstration. For real scraping:
- Review the [APIFY_GUIDE.md](APIFY_GUIDE.md) for instructions
- Ensure compliance with Magicbricks' terms of service
- Check robots.txt before scraping
- Use Apify for reliable, legal scraping

## Thank YOU
